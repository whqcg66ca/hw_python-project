import numpy as np
import pandas as pd
import glob
from spectral import *
import spectral.io.envi as envi
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.cross_decomposition import PLSRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor 
from sklearn.metrics import r2_score, mean_squared_error, root_mean_squared_error,mean_absolute_error, make_scorer
from sklearn.preprocessing import StandardScaler as xscaler

#%% Step 1: Read data 
# The main code seems to use the above functions to process hyperspectral images, 
# extract features, and apply PLS regression for different numbers of components. Results are then saved to a CSV file.

disk='G:'
output_path = disk + r"\2_HSI_Root_Rot\Data_Drone\Output2024"
file_import =disk+ r"\2_HSI_Root_Rot\Data_Drone\Output2024\dataframe_final.csv"
# Read the CSVs
dataframe = pd.read_csv(file_import)

X = dataframe.iloc[1:, 2:-1].to_numpy()
Y = dataframe.iloc[1:, -1].to_numpy()
Z = dataframe.iloc[1:, 0].to_numpy()

print(X.shape)
print(Y.shape)
print(Z.shape) #Plopt number

#%% Step 2: Machine learning model
n_train_r2_mean = []
n_test_r2_mean = []
n_train_r2_std = []    
n_test_r2_std = []
n_list = []

for n in range (1, 30, 1):
    #PLS model specs
    plsmodel = PLSRegression(n_components = n, max_iter=1000)
    
    trainscores_list = []
    testscores_list = []
    
    #K-Fold cross validation
    for i in range(10):
        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)
        trainscores = cross_val_score(plsmodel, X_train, Y_train, cv=5, scoring='r2')
        pls = plsmodel.fit(X_train, Y_train)
        Y_pred = pls.predict(X_test)
        testscores = r2_score(Y_test, np.reshape(Y_pred, (len(Y_pred))))
        trainscores_list.append(trainscores)
        testscores_list.append(testscores)
        
    print("Number of components : " + str(n))
    print("Training Stats")
    print("R2 mean: "+str(np.mean(trainscores_list)*100))
    print("R2 std: "+str(np.std(trainscores_list)*100))
    print("Test Stats")
    print("R2 mean: "+str(np.mean(testscores_list)*100))
    print("R2 std: "+str(np.std(testscores_list)*100))
    n_train_r2_mean.append(np.mean(trainscores_list)*100)
    n_test_r2_mean.append(np.mean(testscores_list)*100)
    n_train_r2_std.append(np.std(trainscores_list)*100)    
    n_test_r2_std.append(np.std(testscores_list)*100)
    n_list.append(n)
    
    
df = pd.DataFrame(list(zip(n_list, n_train_r2_mean, n_train_r2_std, n_test_r2_mean, n_test_r2_std)), columns =['Number of Components','Train Mean', 'Train STD', 'Test Mean', 'Train STD'])
df.to_csv(output_path+r'\Statistic.csv', index = False)

#%% Grid search for hyperparameter tuning

# 1️⃣ Split dataset once for outer evaluation
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=42)

# 2️⃣ Define model and grid of hyperparameters
pls = PLSRegression(max_iter=1000)
param_grid = {'n_components': list(range(1, 30))}

# 3️⃣ Define scorer (use R²)
r2_scorer = make_scorer(r2_score)

# 4️⃣ Grid search with 5-fold cross-validation
grid = GridSearchCV(
    estimator=pls,
    param_grid=param_grid,
    scoring=r2_scorer,
    cv=5,
    n_jobs=-1,
    return_train_score=True
)
grid.fit(X_train, Y_train)

# 5️⃣ Best model and results
print("\n✅ Best number of components:", grid.best_params_['n_components'])
print("Best cross-validated R²:", grid.best_score_)

# 6️⃣ Evaluate on independent test set
best_pls = grid.best_estimator_
Y_pred = best_pls.predict(X_test).ravel()
r2_test = r2_score(Y_test, Y_pred)
print("Independent Test R²:", r2_test)

# 7️⃣ Extract CV results for plotting
cv_results = grid.cv_results_
n_components = [p['n_components'] for p in cv_results['params']]
train_scores = cv_results['mean_train_score']
test_scores = cv_results['mean_test_score']

# 8️⃣ Plot R² vs n_components
plt.figure(figsize=(7,5))
plt.plot(n_components, train_scores, 'o-', label='Train R² (CV mean)')
plt.plot(n_components, test_scores, 's-', label='Validation R² (CV mean)')
plt.xlabel('Number of PLS Components')
plt.ylabel('R² Score')
plt.title('Grid Search for PLSRegression Components')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 9️⃣ (Optional) Scatter plot for best model
plt.figure(figsize=(6.5,6.5))
plt.scatter(Y_test, Y_pred, s=18, alpha=0.7)
plt.plot([0,7],[0,7],'--',color='gray')
plt.xlim(0,7)
plt.ylim(0,7)
plt.xlabel('Measured Y')
plt.ylabel('Estimated Y')
plt.title(f"Best Model (n={grid.best_params_['n_components']}) | R²={r2_test:.3f}")
plt.axis('equal')
plt.show()


#%% Random Forest
X_combined=X
y_combined=Y

##################################################
# Option -2:  Split the training and test dateset
# Set random seed for reproducibility
np.random.seed(10) #50
# Split data into training and testing sets
splitRatio = 0.8
splitIdx = np.random.permutation(len(X_combined ))
trainIdx = splitIdx[:int(splitRatio * len(X_combined ))]
testIdx = splitIdx[int(splitRatio * len(X_combined )):] 
X_train, X_test = X_combined [trainIdx], X_combined [testIdx]
y_train, y_test = y_combined[trainIdx], y_combined[testIdx]
###############################################

# %% Step 3: Regression models 
# Feature Scaling for x, rather than y
sc = xscaler() # replace the standardscaler as sc
x_train = sc.fit_transform(X_train) # maybe better to change to different varibale name, standardscaler.fit_transform is scale the training dataset
x_test = sc.transform(X_test) # standardscaler.transform is to scale the test dataset. It is reasonable that both the training and test datasets need to scaled in the same method


# Define the parameter grid for GridSearchCV
param_grid = {
    'n_estimators': range(5,100,20),      # Number of trees
    'max_depth': [10, 20, 30],     # Maximum depth of each tree
    'max_leaf_nodes': [10, 20, 30], # Maximum number of leaf nodes
    'max_features': ['auto', 'sqrt', 'log2', None]
}

# Initialize the Random Forest Regressor model
rf_model = RandomForestRegressor(random_state=42)

# Set up the GridSearchCV
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, 
                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)

# Fit the GridSearchCV
grid_search.fit(x_train, y_train)

# Get the best parameters and model from grid search
best_params = grid_search.best_params_
best_rf_model = grid_search.best_estimator_

# Predict using the best model
y_pred = best_rf_model.predict(x_test)


#%% Step 4: Evaluate the performance of the algorithms

# Evaluate model performance
r_squared = r2_score(y_test, y_pred.flatten())
rmse = root_mean_squared_error(y_test, y_pred.flatten())
cor = np.corrcoef(y_test, y_pred.flatten())

print(f'R2 on Test Data: {r_squared:.4f}')
print(f'RMSE: {rmse:.4f}')


# Plot actual vs predicted
plt.figure()
plt.scatter(y_test, y_pred, c='k', marker='o')
plt.text(6, 1.5, rf'$R^2 = {r_squared:.2f}$')
plt.text(6, 1, f'RMSE = {rmse:.2f}')
plt.xlabel('Visual Rating')
plt.ylabel('Estimated Root Rot')
# plt.title('Pea Root Rot')
plt.xlim([0, 8])
plt.ylim([0, 8])
plt.show()

# Save the model to a file
# with open(r'L:\HSI_Root_Rot\Method\rf_model2.pkl', 'wb') as f:
#     pickle.dump(rf_model, f)


#%% Step 5: Variable Importance/this could be very interesting for your paper

####### Option 1: unsorted importance
importances_rf = best_rf_model.feature_importances_  # the summation of the importance equal to 1
# Normalize VIP scores between 0 and 1
importances_rf_norm = (importances_rf - np.min(importances_rf)) / (np.max(importances_rf) - np.min(importances_rf))


filepath_1=disk+r'\2_HSI_Root_Rot\Data_Drone\HSI_20240704_PeaRootRot (FRR)\PeasRootRotHSI2024_Pika_L_1-radiance-CorrectFromFlatReference.bip.hdr'
filepath_2=disk+r'\2_HSI_Root_Rot\Data_Drone\HSI_20240704_PeaRootRot (FRR)\PeasRootRotHSI2024_Pika_L_1-radiance-CorrectFromFlatReference.bip'

# 1) Open ENVI image (memory-mapped; no full load)
img = envi.open(filepath_1, filepath_2)
# 2) Get wavelengths if present
wavelengths = np.array([float(w) for w in img.metadata.get('wavelength', [])])  

plt.figure()
plt.scatter(wavelengths, importances_rf_norm, c='k', marker='x')
mx = 1
plt.axvline(x=400, color='b')
plt.axvline(x=500, color='g')
plt.axvline(x=600, color='r')
plt.axvline(x=680, color='k')
plt.axvline(x=750, color='m')
plt.axvline(x=970, color='y')
plt.xlabel('Wavelength (nm)')
plt.ylabel('Importance of wavelength')
plt.ylim([0, mx])
plt.xlim([300, 1100])
plt.show()